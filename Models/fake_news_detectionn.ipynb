{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_NJFAci-jVg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import spacy\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQQR2ty4-8fx",
        "outputId": "1ecc49a3-740d-4292-8cd1-919db14c3100"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfpOB4WF_ukh"
      },
      "outputs": [],
      "source": [
        "# Load Dataset with proper encoding and error handling\n",
        "true_news = pd.read_csv(\"True.csv\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
        "fake_news = pd.read_csv(\"Fake.csv\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
        "\n",
        "# Drop any NaN values\n",
        "true_news.dropna(inplace=True)\n",
        "fake_news.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcd5p7q3DH89",
        "outputId": "b31e2323-47c1-41b6-dbbf-8cf4118ec4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN_Okxyy_2-Y"
      },
      "outputs": [],
      "source": [
        "# Labeling data\n",
        "true_news['label'] = 1  # Real news\n",
        "fake_news['label'] = 0  # Fake news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGe4vGav_7Y0"
      },
      "outputs": [],
      "source": [
        "# Merge datasets\n",
        "news_data = pd.concat([true_news, fake_news], axis=0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6HX47MSAA2k"
      },
      "outputs": [],
      "source": [
        "# Shuffle data\n",
        "news_data = news_data.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eogIxT6GAGrp"
      },
      "outputs": [],
      "source": [
        "# Text Preprocessing Function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text inside brackets\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\n', '', text)  # Remove new lines\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "news_data['text'] = news_data['title'] + ' ' + news_data['text']\n",
        "news_data['text'] = news_data['text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6kam02rATBt"
      },
      "outputs": [],
      "source": [
        "# Tokenization and stopword removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "news_data['text'] = news_data['text'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrq2B6xRAnR1"
      },
      "outputs": [],
      "source": [
        "# Splitting Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(news_data['text'], news_data['label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m65qlpn9Asbt"
      },
      "outputs": [],
      "source": [
        "# Tokenizing Text\n",
        "max_words = 5000\n",
        "max_length = 200\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUKJPomyA83S",
        "outputId": "a815b821-c13a-4de4-bfdb-59a6b330afd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128, input_length=max_length),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    LSTM(32),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghUc3ZCNBBkF"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvO9HkbeBPbw",
        "outputId": "3a2a49ab-9d97-4f4d-dfda-8d9d017e846f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 443ms/step - accuracy: 0.9018 - loss: 0.2604 - val_accuracy: 0.9901 - val_loss: 0.0370\n",
            "Epoch 2/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 448ms/step - accuracy: 0.9931 - loss: 0.0289 - val_accuracy: 0.9933 - val_loss: 0.0310\n",
            "Epoch 3/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 464ms/step - accuracy: 0.9955 - loss: 0.0194 - val_accuracy: 0.9943 - val_loss: 0.0287\n",
            "Epoch 4/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 450ms/step - accuracy: 0.9980 - loss: 0.0079 - val_accuracy: 0.9949 - val_loss: 0.0233\n",
            "Epoch 5/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 451ms/step - accuracy: 0.9974 - loss: 0.0104 - val_accuracy: 0.9914 - val_loss: 0.0379\n",
            "Epoch 6/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 527ms/step - accuracy: 0.9969 - loss: 0.0131 - val_accuracy: 0.9884 - val_loss: 0.0561\n",
            "Epoch 7/10\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 446ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.9943 - val_loss: 0.0268\n"
          ]
        }
      ],
      "source": [
        "# Train Model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit(X_train_padded, y_train, epochs=10, batch_size=64, validation_data=(X_test_padded, y_test), callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxjBdZsgOgbn",
        "outputId": "0fc6d04e-1d5b-4632-e0dc-b045329fb235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save Model\n",
        "model.save(\"fake_news_detector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXsJwTBXOxCg",
        "outputId": "e156ba16-1b3c-4b14-de97-bfd62a0f97ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Load Trained Model\n",
        "model = load_model(\"fake_news_detector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-pxFNlvO1OJ",
        "outputId": "54058173-1c01-41ab-a36d-5a55f2fd27ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9948 - loss: 0.0252\n",
            "Test Accuracy: 0.9943\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp4cLTvAAeYW",
        "outputId": "6022e28e-1630-405d-98b4-1b5638a4122a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
            "\n",
            "Prediction: Fake News ❌\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "\n",
            "Prediction: Fake News ❌\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\n",
            "Prediction: Real News ✅\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "\n",
            "Prediction: Fake News ❌\n"
          ]
        }
      ],
      "source": [
        "def real_time_prediction():\n",
        "    while True:\n",
        "        article = input(\"\\nEnter a news article (or type 'exit' to quit): \")\n",
        "        if article.lower() == 'exit':\n",
        "            print(\"Exiting... Thank you!\")\n",
        "            break\n",
        "\n",
        "        # Preprocess input text\n",
        "        article = preprocess_text(article)\n",
        "        article = remove_stopwords(article)\n",
        "        article_seq = tokenizer.texts_to_sequences([article])\n",
        "        article_padded = pad_sequences(article_seq, maxlen=max_length)\n",
        "\n",
        "        # Predict\n",
        "        prediction = model.predict(article_padded)\n",
        "        result = \"Real News ✅\" if prediction[0][0] > 0.5 else \"Fake News ❌\"\n",
        "\n",
        "        print(f\"\\nPrediction: {result}\")\n",
        "\n",
        "# Run real-time prediction\n",
        "real_time_prediction()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}